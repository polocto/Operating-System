# **Policies**
After low-level **mechanicsms** we are now going to study the high-level **policies**.

    How should we develop a basic framework for thinking about scheduling policies? What are the key assumption? What metrics are important? What basic approaches have been used in the earliest of computer systems?

## **Workload Assumptions**
Workload = *charge de travail*

* Each job **runs** for the **same amount of time**
* All jobs **arrive** at the **same time**
* Once started, each job **runs to completion**
* All jobs **only use the CPU** *(i.e., they perform no I/O)*
* The **run-time** of each job is **known**
***
## **Scheduling Metrics**
A ***metric*** is something that we use to *mesure* something.
To enable us to compare different **scheduling policies** we will use a **scheduling metric**.

We will use, for now, one single metric: **turnaround time** *(is a performance metric)*.

> ***Turnaround time = Time of completion - Time of arrival***

Another interesting metric is **fairness** *(performance and fairness are often at odd)*. A **scheduler** may **optimise performance** but **decreasing fairness**.
***
## **First In, First Out *(FIFO)***
    Non-preemptive scheduler
**FIFO** is simple, and easy to implement and while each jobs begin at the same time and have the same time of completion it works pretty well. for exemple *A*, *B* and *C* last **10 sec each** *(**same workload**)*. *A* finishes at 10 sec, *B* at 20 sec and *C* at 30 sec.
>**Average timearound is 20 sec**.

If *A*, *B* and *C* have **different workload**:
* *A* = 100 sec
* *B* = 110 sec
* *C* = 120 sec
>**Average turnaround = 110 sec**

This refferes as the **convoy effect** where a number of **short** consumers of a resource get queud **behind a heavyweight** resource consumer.
***
## **Shortest Job First *(SJF)***
    Non-preemptive scheduler
>
    Shortest Job First represents a general scheduling principle that can be applied to any system where the preceived turnaround time per customer matters.
If *A*, *B* and *C* have **different workload**:
* *A* = 100 sec
* *B* = 110 sec
* *C* = 120 sec

**SJF** will reorder the jobs to **B -> C -> A**.
The **turnaround** of each jobs will be:
* *B* = 10 sec
* *C* = 20 sec
* *A* = 120 sec

>**Average turnaround = 50 sec**

More than a factor of 2 **improvement**.

If the fact that all **jobs arrive at the same time** is true **SJF** would be **optimal** but in reality jobs could **arrived at any time**. This could end with a similar schema as in **FIFO** with **different workload** for each jobs and **bad average turnaround** if *A* arrives before *B* and *C*.
***
## **Shortest Time-to-Completion First *(STCF/PSJF)***
    Preemptive scheduler
    Shortest Time-to-Completion First = Preemtive Shortest Job First (PSJF)

To address this concern, we will need first to **relax** assumption 3 *(**One started, each job runs to completion**)*. We can now **stop** *(preempt)* **a process to run another one**.
```c++
//This is if process Ais actually running and process B is the next one in the waiting list
if (A.getTimeCompletion() > B.getTimeCompletion())
{
    A.stop();
    B.runs();
}
```

By using this method we found the same result as in the **SJF** when they all start at the same time : 
The **turnaround** of each jobs will be:
* *B* = 10 sec (20-10)
* *C* = 20 sec (30-10)
* *A* = 120 sec (120-0)

>**Average turnaround = 50 sec**
***
## **A New Metric: Response Time**
    Preemptive scheduler
If we knew job lengths, and that jobs only used the CPU, and our only metric was **turnaround** time, **STCF** would be a great policy. Now users would demand an **interactive performance** from the system. And thus, a new metric was born: **response time**.

>**ResponseTime = timeFirstRun - timeArrival**

* **STCF** = **Bad** for **Response Time**
    * *A* to completion
    * *B* to completion
    * *C* to completion
    > **Good** for **turnaround** but **bad** for **response time** and **interactivity**
* **Round Robin** = **Good** for **Response Time**
    * *A* -> *B* -> *C*
    * *A* -> *B* -> *C*
    * ...    
>
    How can we built a scheduler that is sensitive to response time?
***
## **Round Robin *(RR)***
    A scheduling algorithme

Instead of running jobs to completion **RR** runs a job for **time slice** *(**scheduling quantum**)*. It runs jobs in the queue and do it again and again until the jobs are finished.
***
### <i>Amortization</i>
The general technique of <b>amortization</b> is commonly used un systems when there is a fixed cost to some operation. For example, if the <b>time slice</b> is set to <b>10 ms</b> and <b>context-switch</b> cost <b>1 ms</b> (<b>10% of the <i>time slice</i></b>). If we want to <b>amortize it</b> we will <b>increase <i>time slice</i> to <i>100 ms</i> </b><i>(<b>context-switch</b> is now <b>1%</b> of <b>time slice</b>)</i>.
***
We should find the good **time slice** so the system is **responsive** and **amortize**.

Looking figure 7.7, *A* finishes at **13**, *B* at **14** and *C* at **15**
> turnaround time = 14 sec

- **RR** is one of the **worst policies** if **turnaround** is our only **metric**.
    - *More generally, any **fair policies** will perform poorly on metrics such as **turnaround time**.*
***
### <i>Overlap</i>
<b>Overlap</b> operations to maximize the utilisation of systems. It is useful when performing disk **I/O** or **sending messages** to remote machines. It improves thes overall utilization and efficiency of the system.
***
If we value the fairness it will lower response time, and vis versa, this is a common **trade-off**.

    We have developed two types of scheduler. The first type (SJF, STCF) optimizes turnaround time but is bad for response time. The second type (RR) optimizes response time but is bad for turnaround. And we still have two assumptions which need to be relaxed:
    - Jobs do no I/O
    - Run-time of each job is known

    Let's tackle thos assumptions next.
***
## **Incoporating I/O**
During **I/O operation** the **CPU is blocked** for multiple ms depending on the number of datas the program needs to access. So while a process access to **I/O** the scheduler should run another process on the CPU.

The scheduler also has to make the decision when **I/O** completes. An interrupt is raised the **OS** runs and moves the process to the **ready state**.
> How should the **OS treat the job**?

While ***A* reads I/O** the **OS** should **runs *B*** (**overlap**).
***
## **No More Oracle**
With a basic approach to **I/O** in place, we come to our first assumption: that the scheduler **knows the length of each job**. As we said before, this is likely **the worst assumption** we could make. In fact, in general-purpose OS (like the ones we care about), th OS usually knows very litlle about the length of each job. 

>How can we build an approach that behaves like  SJF/STCF without such *a priori* knowledge?

>How can we incorporate some of the ideas we have seen with the **RR** scheduler so that **response time** is also quite good?
***
## **Summary**

We have introduced the basic ideas behind scheduling and developed two families of approaches. The first **runs the shortest job** remaining and thus optimizies **tunaround time**; the second **alternates between all jobs** and thus **optimizes response time**. Both are bad where the other is good, alas, an inheritent **trade-off** common in systems. We have also seen how we might **incorporate I/O** into the picture, but have still not solved the problem of the fundamental inhability of the OS to see in the future. Shortly, we will see how to overcome this problem, by building a scheduler that uses the recent past to predict the future. This scheduler is known as the **multi-level feedback queue**, and it is the topic of the next chapter.